\documentclass{article}
\usepackage[margin=1in,a4paper]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[cyr]{aeguill}
\usepackage[francais]{babel}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{gensymb}
\usepackage{enumitem,amssymb}
\newlist{checks}{itemize}{2}
\setlist[checks]{label=$\square$}
\usepackage{graphicx}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{pdfpages}
\usepackage{pgfplots}
\usepackage{multicol}
\pgfplotsset{compat=newest}
\usetikzlibrary{calc}
\usepackage{pgfplots}
\usepackage{mathtools}
\usepackage{array}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{tabularx}
\usepackage{fancyhdr}
\usepackage{pst-func}
\usepackage{xcolor}
\usepackage{nicefrac}
\usepackage{mdframed}
\usepackage[boxed,vlined]{algorithm2e}
\usepackage{cleveref}
% \usepackage{graphicx}
\newcommand{\Lim}[1]{\raisebox{0.5ex}{\scalebox{1}{$\displaystyle \lim_{#1}\;$}}}
\usepackage{graphicx}
\usepackage{tkz-tab}

\newcommand{\Tr}{\text{Tr}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\w}{\omega}
\newcommand{\p}{\partial}
\newcommand{\Pn}{\mathbb{P}}
\newcommand{\cross}{\times}
\newcommand{\Col}{\text{Col}}
\DeclareMathOperator{\sinc}{sinc}
\newcommand{\bigzero}{\makebox(0,0){\text{\huge0}}}
\DeclareMathOperator{\interior}{int}
\DeclareMathOperator{\adh}{adh}
\DeclareMathOperator{\argcosh}{argcosh}
\DeclareMathOperator{\argsinh}{argsinh}
\DeclareMathOperator{\Ima}{Im}
\DeclareMathOperator{\Vect}{Vect}
\usepackage{mathtools, stmaryrd}
\usepackage{xparse} \DeclarePairedDelimiterX{\Iintv}[1]{\llbracket}{\rrbracket}{\iintvargs{#1}}
\NewDocumentCommand{\iintvargs}{>{\SplitArgument{1}{,}}m}
{\iintvargsaux#1} %
\NewDocumentCommand{\iintvargsaux}{mm} {#1\mkern1.5mu..\mkern1.5mu#2}


\title{Students for Students \\Algèbre linéaire - Corrigé}
\author{}
\date{}

\begin{document}
\tikzset{%
   point/.style = {fill=black,inner sep=1pt, circle, minimum width=3pt,align=right,rotate=60},
   } 
\tikzstyle{weight} = [font=\scriptsize]  
\tikzstyle{vertex}=[circle,fill=blue!20]

\maketitle

\subsection*{Exercice 1}
\noindent 1) La seconde ligne comporte un $1$ comme premier coefficient, que nous choisirons comme premier pivot.
\begin{align*}
    \begin{bmatrix}
    4 & -1 & 3 & -6\\
    1 & -2 & 1 & 0\\
    0 & 5 & -2 & 8
    \end{bmatrix} 
    \overset{L_1 \leftrightarrow L_2}{\sim}
    &\begin{bmatrix}
    \color{blue}1 & -2 & 1 & 0\\
    4 & -1 & 3 & -6\\
    0 & 5 & -2 & 8
    \end{bmatrix}
    \overset{L_2 \to L_2 - 4L_1}{\sim}
    \begin{bmatrix}
    \color{blue}1 & -2 & 1 & 0\\
    0 & 7 & -1 & -6\\
    0 & 5 & -2 & 8
    \end{bmatrix}
\end{align*}
\noindent Pour la seconde colonne, il n'y a pas de meilleur choix de pivot, les deux choix possibles mènent à des calculs... peu plaisants.
\begin{align*}
    \begin{bmatrix}
    \color{blue}1 & -2 & 1 & 0\\
    0 & 7 & -1 & -6\\
    0 & 5 & -2 & 8
    \end{bmatrix}
    \overset{L_3 \leftrightarrow L_2}{\sim}
    &\begin{bmatrix}
    \color{blue}1 & -2 & 1 & 0\\
    0 & \color{blue}5 & -2 & 8\\
    0 & 7 & -1 & -6
    \end{bmatrix}
    \overset{L_2 \to \frac{1}{5}L_2}{\sim}
    \begin{bmatrix}
    \color{blue}1 & -2 & 1 & 0\\
    0 & \color{blue}1 & -\frac{2}{5} & \frac{8}{5}\\
    0 & 7 & -1 & -6
    \end{bmatrix}\\
    \overset{L_3 \to L_3 - 7L_2}{\sim}
    &\begin{bmatrix}
    \color{blue}1 & -2 & 1 & 0\\
    0 & \color{blue}1 & -\frac{2}{5} & \frac{8}{5}\\
    0 & 0 & \frac{14}{5}-1 & -6-\frac{56}{5}
    \end{bmatrix}
    =
    \begin{bmatrix}
    \color{blue}1 & -2 & 1 & 0\\
    0 & \color{blue}1 & -\frac{2}{5} & \frac{8}{5}\\
    0 & 0 & \color{blue}\frac{9}{5} & -\frac{86}{5}
    \end{bmatrix}\\
    \overset{L_3 \to \frac{5}{9}L_3}{\sim}
    &\begin{bmatrix}
    \color{blue}1 & -2 & 1 & 0\\
    0 & \color{blue}1 & -\frac{2}{5} & \frac{8}{5}\\
    0 & 0 & \color{blue}1 & -\frac{86}{9}
    \end{bmatrix}
    \overset{L_2 \to L_2 + \frac{2}{5}L_3}{\sim}
    \begin{bmatrix}
    \color{blue}1 & -2 & 1 & 0\\
    0 & \color{blue}1 & 0 & \frac{8}{5} - \frac{2}{5}\frac{86}{9}\\
    0 & 0 & \color{blue}1 & -\frac{86}{9}
    \end{bmatrix}\\
    =
    &\begin{bmatrix}
    \color{blue}1 & -2 & 1 & 0\\
    0 & \color{blue}1 & 0 & -\frac{20}{9}\\
    0 & 0 & \color{blue}1 & -\frac{86}{9}
    \end{bmatrix}
    \overset{L_1 \to L_1 - L_3}{\sim}
    \begin{bmatrix}
    \color{blue}1 & -2 & 0 & \frac{86}{9}\\
    0 & \color{blue}1 & 0 & -\frac{20}{9}\\
    0 & 0 & \color{blue}1 & -\frac{86}{9}
    \end{bmatrix}\\
    \overset{L_1 \to L_1 + 2L_2}{\sim}
    &\begin{bmatrix}
    \color{blue}1 & 0 & 0 & \frac{46}{9}\\
    0 & \color{blue}1 & 0 & -\frac{20}{9}\\
    0 & 0 & \color{blue}1 & -\frac{86}{9}
    \end{bmatrix}
\end{align*}\\
La forme échelonnée réduite compte un pivot par ligne, l'application matricielle associée est donc surjective. La quatrième colonne ne comporte pas de pivot, ainsi l'application associée n'est pas injective.\\

\noindent 2) Le $1$ en tête de la première ligne nous invite à le choisir comme pivot, bien que le choix du $2$ en deuxième ligne est également valable. Comme nous prenons souvent $1$ comme pivot, prenons ici $2$ pour changer.
\begin{align*}
    \begin{bmatrix}
    1 & -5 & 4 & -3\\
    2 & -7 & 3 & -2\\
    -2 & 1 & 7 & -1
    \end{bmatrix}
    \overset{L_1 \leftrightarrow L_2 \leftrightarrow L_3}{\sim}
    &\begin{bmatrix}
    \color{blue}2 & -7 & 3 &  -2 \\
    -2 & 1 & 7 &  -1 \\
    1 & -5 & 4 &  -3
    \end{bmatrix}
    \overset{L_2 \rightarrow L_2 +L_1}{\sim}
    \begin{bmatrix}
    \color{blue}2 & -7 & 3 &  -2 \\
    0 & -6 & 10 &  -3 \\
    1 & -5 & 4 &  -3
    \end{bmatrix}\\
    \overset{L_1 \rightarrow \frac{1}{2}L_1}{\sim}
    &\begin{bmatrix}
   \color{blue} 1 & -7/2 & 3/2 &  -1 \\
    0 & -6 & 10 &  -3 \\
    1 & -5 & 4 &  -3
    \end{bmatrix} 
    \overset{L_3 \rightarrow L_3 - L_1}{\sim}
    \begin{bmatrix}
    \color{blue}1 & -7/2 & 3/2 & -1 \\
    0 & -6 & 10 &  -3 \\
    0 & -3/2 & 5/2 &  -2
    \end{bmatrix}\\
   \overset{L_3 \rightarrow -4L_3}{\sim}
    &\begin{bmatrix}
    \color{blue}1 & -7/2 & 3/2 &  -1 \\
    0 & \color{blue}-6 & 10 &  -3 \\
    0 & 6 & -10 & 8 %yeet
    \end{bmatrix} 
    \overset{L_3 \rightarrow L_3+L_2}{\sim}
    \begin{bmatrix}
    \color{blue}1 & -7/2 & 3/2 & -1 \\
    0 & \color{blue}-6 & 10 & -3 \\
    0 & 0 & 0 & \color{blue}5
    \end{bmatrix}
\end{align*}
Remarquons qu'ici, nous avons déjà une forme échelonnée de la matrice, ce qui nous sera utile plus tard dans la série. Continuons jusqu'à la forme échelonnée réduite :
\begin{align*}
    \begin{bmatrix}
    \color{blue}1 & -7/2 & 3/2 & -1 \\
    0 & \color{blue}-6 & 10 & -3 \\
    0 & 0 & 0 & \color{blue}5
    \end{bmatrix}
    \overset{L_3 \to \frac{1}{5}L_3}{\sim}
    &\begin{bmatrix}
    \color{blue}1 & -7/2 & 3/2 & -1 \\
    0 & \color{blue}-6 & 10 & -3 \\
    0 & 0 & 0 & \color{blue}1
    \end{bmatrix}
    \sim
    \begin{bmatrix}
    \color{blue}1 & -7/2 & 3/2 & 0 \\
    0 & \color{blue}-6 & 10 & 0 \\
    0 & 0 & 0 & \color{blue}1
    \end{bmatrix}\\
    \overset{L_2 \to -\frac{1}{6}L_2}{\sim}
    &\begin{bmatrix}
    \color{blue}1 & -7/2 & 3/2 & 0 \\
    0 & \color{blue}1 & -\frac{5}{3} & 0 \\
    0 & 0 & 0 & \color{blue}1
    \end{bmatrix}
    \overset{L_1 \to L_1 + \frac{7}{2}L_2}{\sim}
    \begin{bmatrix}
    \color{blue}1 & 0 & -\frac{13}{3} & 0 \\
    0 & \color{blue}1 & -\frac{5}{3} & 0 \\
    0 & 0 & 0 & \color{blue}1
    \end{bmatrix}
\end{align*}\\

\noindent La forme échelonnée réduite compte un pivot par ligne, l'application matricielle associée est donc surjective. La troisième colonne ne comporte pas de pivot, ainsi l'application associée n'est pas injective.\\

\noindent 3) Utilisons le $1$ en première ligne.
\begin{align*}
    \begin{bmatrix}
    \color{blue}1 & -3 & 2 \\
    -5 & -2  & 7  \\
    4 & -10  & 6 \\
    10 & -7 & -3
    \end{bmatrix}
    \overset{\substack{L_2 \to L_2 + 5L_1 \\ L_3 \to L_3 - 4L_1\\ L_4 \to L4 - 10L_1}}{\sim}
    &\begin{bmatrix}
    \color{blue}1 & -3 & 2 \\
    0 & -17  & 17  \\
    0 & 2  & -2 \\
    0 & 23 & -23
    \end{bmatrix}
    \overset{\substack{L_2 \to -\frac{1}{17}L_2 \\ L_3 \to \frac{1}{2}L_3 \\ L_4 \to \frac{1}{23}L_4}}{\sim}
    \begin{bmatrix}
    \color{blue}1 & -3 & 2 \\
    0 & \color{blue}1  & -1  \\
    0 & 1  & -1  \\
    0 & 1  & -1 
    \end{bmatrix}\\
    \overset{\substack{L_3 \to L_3 - L_2 \\ L_4 \to L_4 - L_2}}{\sim}
    &\begin{bmatrix}
    \color{blue}1 & -3 & 2 \\
    0 & \color{blue}1  & -1  \\
    0 & 0  & 0  \\
    0 & 0  & 0 
    \end{bmatrix}
    \overset{L_1 \to L_1 + 3L_2}{\sim}
    \begin{bmatrix}
    \color{blue}1 & 0 & -1 \\
    0 & \color{blue}1  & -1  \\
    0 & 0  & 0  \\
    0 & 0  & 0 
    \end{bmatrix}
\end{align*}\\

\noindent Il n'y a ni un pivot pour chaque colonne ni un pivot pour chaque ligne, l'application associée n'est ni injective ni surjective.\\

\noindent 4) Mettons en évidence le $1$ puis continuons :
\begin{align*}
    \begin{bmatrix}
    -4 & 5 & 9\\
    1 & -2 & 1\\
    0 & 2 & -8 
    \end{bmatrix}
    \overset{L_1 \leftrightarrow L_2}{\sim}
    &\begin{bmatrix}
    \color{blue}1 & -2 & 1\\
    -4 & 5 & 9\\
    0 & 2 & -8 
    \end{bmatrix}
    \overset{L_4 \to L_4 + 4L_1}{\sim}
    \begin{bmatrix}
    \color{blue}1 & -2 & 1\\
    0 & -3 & 13\\
    0 & 2 & -8 
    \end{bmatrix}
\end{align*}
Remarquons la simplification par $2$ possible en dernière ligne :
\begin{align*}
    \begin{bmatrix}
    \color{blue}1 & -2 & 1\\
    0 & -3 & 13\\
    0 & 2 & -8 
    \end{bmatrix}
    \overset{L_3 \to \frac{1}{2}L_3}{\sim}
    &\begin{bmatrix}
    \color{blue}1 & -2 & 1\\
    0 & -3 & 13\\
    0 & 1 & -4 
    \end{bmatrix}
    \overset{L_3 \leftrightarrow L_2}{\sim}
    \begin{bmatrix}
    \color{blue}1 & -2 & 1\\
    0 & \color{blue}1 & -4 \\
    0 & -3 & 13
    \end{bmatrix}\\
    \overset{L_3 \to L_3 + 3L_2}{\sim}
    &\underbrace{\begin{bmatrix}
    \color{blue}1 & -2 & 1\\
    0 & \color{blue}1 & -4 \\
    0 & 0 & \color{blue}1
    \end{bmatrix}}_{(*)}
    \sim
    \begin{bmatrix}
    \color{blue}1 & 0 & 0\\
    0 & \color{blue}1 & 0 \\
    0 & 0 & \color{blue}1
    \end{bmatrix}
\end{align*}
Pour cette dernière équivalence, nous n'avons pas à faire les calculs explicitement : la matrice $(*)$ est carrée et échelonnée avec 3 pivots, un pour chaque ligne (et donc chaque colonne aussi), son application associée est donc inversible, et donc surjective et injective. Aussi, sa forme échelonnée réduite est forcément $I_3$.

\subsection*{Exercice 2}
\noindent 1) En écrivant d'abord la matrice augmentée associée : \begin{align*}
    \begin{bmatrix}
    2 & 0 & -6 & \bigm| & -8 \\
    0 & 1 & 2 & \bigm| & 3 \\
    3 & 6 & -2 & \bigm| & -4
    \end{bmatrix}
    \overset{L_1 \rightarrow \frac{1}{2}L_1}{\sim}
    &\begin{bmatrix}
    \color{blue}1 & 0 & -3 & \bigm| & -4 \\
    0 & 1 & 2 & \bigm| & 3 \\
    3 & 6 & -2 & \bigm| & -4
    \end{bmatrix}
    \overset{L_3 \rightarrow L_3 -3L_1}{\sim}
    \begin{bmatrix}
    \color{blue}1 & 0 & -3 & \bigm| & -4 \\
    0 & \color{blue}1 & 2 & \bigm| & 3 \\
    0 & 6 & 7 & \bigm| & 8
    \end{bmatrix} \\
    \overset{L_3 \rightarrow L_3 -6L_2}{\sim}
    &\begin{bmatrix}
    \color{blue}1 & 0 & -3 & \bigm| & -4 \\
    0 & \color{blue}1 & 2 & \bigm| & 3 \\
    0 & 0 & \color{blue}-5 & \bigm| & -10
    \end{bmatrix}
    \overset{L_3 \rightarrow -\frac{1}{5}L_3}{\sim}
    \begin{bmatrix}
    \color{blue}1 & 0 & -3 & \bigm| & -4 \\
    0 & \color{blue}1 & 2 & \bigm| & 3 \\
    0 & 0 & \color{blue}1 & \bigm| & 2
    \end{bmatrix} \\
    \overset{L_2 \rightarrow L_2 -2L_3}{\sim}
    &\begin{bmatrix}
    \color{blue}1 & 0 & -3 & \bigm| & -4 \\
    0 & \color{blue}1 & 0 & \bigm| & -1 \\
    0 & 0 & \color{blue}1 & \bigm| & 2
    \end{bmatrix}
    \overset{L_1 \rightarrow L_2 +3L_3}{\sim}
    \begin{bmatrix}
    \color{blue}1 & 0 & 0 & \bigm| & 2 \\
    0 & \color{blue}1 & 0 & \bigm| & -1 \\
    0 & 0 & \color{blue}1 & \bigm| & 2
    \end{bmatrix}
\end{align*} 
Le système correspondant à la forme échelonnée réduite est:
$$\begin{cases}
x_1 = 2 \\
x_2 = -1 \\
x_3 = 2
\end{cases}$$
L'ensemble des solutions est donc:
$$S(A,b) = \left\{ \begin{bmatrix} 2 \\ -1 \\ 2 \end{bmatrix} \right\}$$
Notons que la matrice des coefficients possède 3 pivots, soit un par ligne et par colonne. L'application associée est bijective, et ceci explique l'unicité de la solution. \\

\noindent 2) Notons qu'à une permutation de ligne près, cette matrice est celle de la question 2 de l'exercice 1. Nous réécrivons ici son échelonnage :\begin{align*}
    \begin{bmatrix}
    2 & -7 & 3 & \bigm| & -2 \\
    -2 & 1 & 7 & \bigm| & -1 \\
    1 & -5 & 4 & \bigm| & -3
    \end{bmatrix}
    \overset{L_2 \rightarrow L_2 +L_1}{\sim}
    &\begin{bmatrix}
    \color{blue}2 & -7 & 3 & \bigm| & -2 \\
    0 & -6 & 10 & \bigm| & -3 \\
    1 & -5 & 4 & \bigm| & -3
    \end{bmatrix}
    \overset{L_1 \rightarrow \frac{1}{2}L_1}{\sim}
    \begin{bmatrix}
   \color{blue} 1 & -7/2 & 3/2 & \bigm| & -1 \\
    0 & -6 & 10 & \bigm| & -3 \\
    1 & -5 & 4 & \bigm| & -3
    \end{bmatrix} \\
    \overset{L_3 \rightarrow L_3 - L_1}{\sim}
    &\begin{bmatrix}
    \color{blue}1 & -7/2 & 3/2 & \bigm| & -1 \\
    0 & -6 & 10 & \bigm| & -3 \\
    0 & -3/2 & 5/2 & \bigm| & -2
    \end{bmatrix}
    \overset{L_3 \rightarrow -4L_3}{\sim}
    \begin{bmatrix}
    \color{blue}1 & -7/2 & 3/2 & \bigm| & -1 \\
    0 &\color{blue} -6 & 10 & \bigm| & -3 \\
    0 & 6 & -10 & \bigm| & 8 %yeet
    \end{bmatrix} \\
    \overset{L_3 \rightarrow L_3+L_2}{\sim}
    &\begin{bmatrix}
    \color{blue}1 & -7/2 & 3/2 & \bigm| & -1 \\
    0 & \color{blue}-6 & 10 & \bigm| & -3 \\
    0 & 0 & 0 & \bigm| & \color{blue}5
    \end{bmatrix}
\end{align*}
La dernière ligne s'écrit $0x_1 + 0 x_2 + 0x_3 = 5 \implies 0=5$, ce qui est contradictoire, et donc $S(A,b) = \emptyset$. Ainsi, une forme échelonnée ici suffit pour conclure, pas besoin de la forme réduite. \\

\noindent 3) En supposant qu'à présent il n'y a plus besoin des indications en couleur pour les pivots :\begin{align*}
    \begin{bmatrix}
    1 & -4 & 7 & \bigm| & 1 \\
    0 & 3 & -5 & \bigm| & -3 \\
    -2 & 5 & -9 & \bigm| & 1
    \end{bmatrix}
    \overset{L_3 \rightarrow L_3+2L_1}{\sim}
    &\begin{bmatrix}
    1 & -4 & 7 & \bigm| & 1 \\
    0 & 3 & -5 & \bigm| & -3 \\
    0 & -3 & 5 & \bigm| & 3
    \end{bmatrix}
    \overset{L_3 \rightarrow L_3+L_2}{\sim}
    \begin{bmatrix}
    1 & -4 & 7 & \bigm| & 1 \\
    0 & 3 & -5 & \bigm| & -3 \\
    0 & 0 & 0 & \bigm| & 0
    \end{bmatrix} \\
    \overset{\substack{L_1 \rightarrow 5L_1 \\ L_2 \rightarrow 7L_2}}{\sim}
    &\begin{bmatrix}
    5 & -20 & 35 & \bigm| & 5 \\
    0 & 21 & -35 & \bigm| & -21 \\
    0 & 0 & 0 & \bigm| & 0
    \end{bmatrix}
    \overset{\substack{L_1 \rightarrow L_1+L_2 \\ L_2 \rightarrow \frac{1}{21}L_2}}{\sim}
    \begin{bmatrix}
    5 & 1 & 0 & \bigm| & -16 \\
    0 & 1 & -5/3 & \bigm| & -1 \\
    0 & 0 & 0 & \bigm| & 0
    \end{bmatrix} \\
    \overset{L_1 \rightarrow L_1-L_2}{\sim}
    &\begin{bmatrix}
    5 & 0 & 5/3 & \bigm| & -15 \\
    0 & 1 & -5/3 & \bigm| & -1 \\
    0 & 0 & 0 & \bigm| & 0
    \end{bmatrix}
    \overset{L_1 \rightarrow \frac{1}{5}L_1}{\sim}
    \begin{bmatrix}
    1 & 0 & 1/3 & \bigm| & -3 \\
    0 & 1 & -5/3 & \bigm| & -1 \\
    0 & 0 & 0 & \bigm| & 0
    \end{bmatrix}
\end{align*}
Le système correspondant à la forme échelonnée réduite est:
$$\begin{cases}
x_1 + \frac{1}{3} x_3 = -3 \\
x_2 - \frac{5}{3}x_3 = -1 \\
x_3 \in \R
\end{cases} \iff 
\begin{cases}
x_1 = -\frac{1}{3} x_3 -3 \\
x_2 = \frac{5}{3}x_3 -1 \\
x_3 \in \R
\end{cases}$$
L'ensemble des solutions est alors:
$$S(A,b) = \left\{ \begin{bmatrix} -3 \\ -1 \\ 0 \end{bmatrix} + x_3 \begin{bmatrix} -1/3 \\ 5/3 \\ 1 \end{bmatrix} \ | \ x_3 \in \R \right\}$$

\noindent 4) Le produit matrice-vecteur sera défini pour $n = 2$. \begin{align*}
    \begin{bmatrix}
    2 & 3 & \bigm| & -1 \\
    6 & 5 & \bigm| & 0 \\
    2 & -5 & \bigm| & 7
    \end{bmatrix}
    \overset{\substack{L_2 \rightarrow L_2-3L_1 \\L_3 \rightarrow L_3-L_1}}{\sim}
    &\begin{bmatrix}
    2 & 3 & \bigm| & -1 \\
    0 & -4 & \bigm| & 3 \\
    0 & -8 & \bigm| & 8
    \end{bmatrix}
    \overset{L_3 \rightarrow L_3 -2L_2}{\sim}
    \begin{bmatrix}
    2 & 3 & \bigm| & -1 \\
    0 & -4 & \bigm| & 3 \\
    0 & 0 & \bigm| & 2
    \end{bmatrix}
\end{align*}
La dernière ligne s'écrit $0 x_1 + 0 x_2 = 2 \implies 0=2$, ce qui est contradictoire, et donc $S(A,b) = \emptyset$. \\

\subsection*{Exercice 3}
\noindent Nous échelonnons en utilisant l'algorithme de Gauss pour calculer l'inverse :
$$\begin{bmatrix}
b & 1 & \bigm| & 1 & 0 \\
1 & 0 & \bigm| & 0 & 1
\end{bmatrix} 
\sim
\begin{bmatrix}
b & 1 & \bigm| & 1 & 0 \\
0 & -1 & \bigm| & -1 & b
\end{bmatrix} \sim 
\begin{bmatrix}
b & 0 & \bigm| & 0 & b \\
0 & -1 & \bigm| & -1 & b
\end{bmatrix} \sim
\begin{bmatrix}
1 & 0 & \bigm| & 0 & 1 \\
0 & 1 & \bigm| & 1 & -b
\end{bmatrix} $$
Nous avons fait l'hypothèse $b \neq 0$ dans la dernière étape pour pouvoir diviser par $b$. En traitant le cas $b=0$ séparément, nous remarquons que la formule fonctionne quand même, i.e que $\begin{bmatrix}
0 & 1\\
1 & 0
\end{bmatrix}$ est sa propre inverse. \\
Ceci donne $\begin{bmatrix} b & 1 \\ 1 &  0\end{bmatrix}^{-1} = \begin{bmatrix} 0 & 1 \\ 1 &  -b\end{bmatrix}$, $\forall b \in \R$. \\ 


\subsection*{Exercice 4}
\noindent Pour trouver cette relation, nous allons d'abord échelonner $A$, et lorsque nous arrivons sur des étapes "délicates" (comme par exemple la division par $0$), nous imposerons des conditions sur $a,b,c,d$, qui nous permettrons de continuer.\\
Échelonnons donc $A$ :
$$\begin{bmatrix} 
a & b & \bigm| & 1 & 0 \\
c & d & \bigm| & 0 & 1
\end{bmatrix} \sim 
\begin{bmatrix} 
ac & bc & \bigm| & c & 0 \\
ac & ad & \bigm| & 0 & a
\end{bmatrix} \sim 
\begin{bmatrix} 
ac & bc & \bigm| & c & 0 \\
0 & ad-bc & \bigm| & -c & a
\end{bmatrix} \sim 
\begin{bmatrix} 
a & b & \bigm| & 1 & 0 \\
0 & ad-bc & \bigm| & -c & a
\end{bmatrix}$$
Nous faisons l'hypothèse que $ad-bc \neq 0$ pour pouvoir diviser par cette quantité. Ceci donne:
$$\begin{bmatrix} 
a & b & \bigm| & 1 & 0 \\
0 & 1 & \bigm| & \frac{-c}{ad-bc} & \frac{a}{ad-bc}
\end{bmatrix} \sim 
\begin{bmatrix} 
a & b & \bigm| & 1 & 0 \\
0 & b & \bigm| & \frac{-bc}{ad-bc} & \frac{ab}{ad-bc}
\end{bmatrix} \sim
\begin{bmatrix} 
a & 0 & \bigm| & 1 + \frac{bc}{ad-bc}& \frac{-ab}{ad-bc} \\
0 & b & \bigm| & \frac{-bc}{ad-bc} & \frac{ab}{ad-bc}
\end{bmatrix}$$
Nous avons que $1 + \frac{bc}{ad-bc} = \frac{ad-bc}{ad-bc} + \frac{bc}{ad-bc} = \frac{ad}{ad-bc}$. Donc:
$$\begin{bmatrix} 
a & 0 & \bigm| & \frac{ad}{ad-bc}& \frac{-ab}{ad-bc} \\
0 & 1 & \bigm| & \frac{-c}{ad-bc} & \frac{a}{ad-bc}
\end{bmatrix} \sim
\begin{bmatrix}
1 & 0 & \bigm| & \frac{d}{ad-bc}& \frac{-b}{ad-bc} \\
0 & 1 & \bigm| & \frac{-c}{ad-bc} & \frac{a}{ad-bc}
\end{bmatrix}$$
Finalement, $\displaystyle \begin{bmatrix} a & b \\ c & d \end{bmatrix}^{-1} = \frac{1}{ad-bc} \begin{bmatrix} d & -b \\ -c & a \end{bmatrix}$, sous l'hypothèse $ad-bc \neq 0$. \\

\noindent Revenons à l'exo 3. Par la formule que nous avons démontré:
$$\begin{bmatrix} b & 1 \\ 1 &  0\end{bmatrix}^{-1} = \frac{1}{b\cdot 0 - 1\cdot 1} \begin{bmatrix} 0 & -1 \\ -1 &  b\end{bmatrix} = -\begin{bmatrix} 0 & -1 \\ -1 &  b\end{bmatrix} = \begin{bmatrix} 0 & 1 \\ 1 &  -b\end{bmatrix}$$
Ce qui est bien le résultat trouvé à l'exo 3.


\subsection*{Exercice 5}
\begin{enumerate}
    \item 
    \begin{enumerate}
        \item Une idée que nous pourrions avoir est de ranger les coefficients du polynôme dans un vecteur, car un polynôme est entièrement déterminé par ses coefficients. Ceci donne, pour $p(t) = a_0 + a_1t + \cdots + a_n t^n$:
        $$f_n(p)=(a_{0},a_{1},...,a_{n}) \in \R^{n+1}$$
        De plus, $f_n$ est bijective. En effet, elle est surjective car $\forall x = (x_0, ..., x_n) \in \R^{n+1}$, $p(t) = x_0 + x_1 t + \cdots + x_n t^n$ est tel que $f_n(p) = x$, autrement dit, tout vecteur dans $\R^{n+1}$ possède au moins un antécédent. $f_n$ est aussi injective, car si $p_1 \neq p_2$, alors $f_n(p_1) \neq f_n(p_2)$ (deux polynômes sont égaux ssi (si et seulement si) chacun de leurs coefficients sont égaux, et de manière similaire deux vecteurs sont égaux ssi chacune de leurs entrées sont égales). 
        \item Soient $a(t) = a_0 + a_1t+ \cdots + a_nt^n$ et $b(t) = b_0 + b_1t + \cdots + b_nt^n$, puis $\lambda \in \R$. \\
        $f_n(a + b) = (a_0 + b_0, \cdots, a_n + b_n) = (a_0, \cdots, a_n) + (b_0, \cdots, b_n) = f_n(a) + f_n(b)$.\\
        $f_n(\lambda a) = (\lambda a_0, \cdots, \lambda a_n) = \lambda(a_0, \cdots, a_n) = \lambda f_n(a)$.\\
        
        \noindent Cette propriété est dite celle de linéarité de $f_n$. Vous verrez plus tard dans le semestre que $f_n$ est un \textit{isomorphisme} entre les \textit{espaces vectoriels} $\Pn_n$ et $\R^{n+1}$, i.e une bijection entre ces deux ensembles telle que, du point de vue de l'algèbre linéaire, ces deux ensembles se "ressemblent".
    \end{enumerate}
    \item
    Tâchons de comprendre cette application $g = f_1 \circ T \circ f_2^{-1}$, en la décrivant explicitement. Soit $a = (a_0, a_1, a_2)$, utilisons les définitions des applications $f_2^{-1}, T$ et $f_1$ successivement :
    $$
    f_2^{-1}(a)= f_2^{-1}((a_0,a_1,a_2)) = a_0 + a_1t+ a_2t^2
    $$
    $$
    T\circ f_2^{-1}(a) = (2a_0 + 3a_1)+(a_0 + 4a_2)t
    $$
    $$
    g(a) = f_1 \circ T\circ f_2^{-1}(a) = (2a_0 + 3a_1, a_0 + 4a_2)
    $$
    Observons le membre de droite, et remarquons que:
    $$\begin{bmatrix} 2a_0 + 3a_1 \\ a_0 + 4a_2\end{bmatrix} = 
    \begin{bmatrix} 2 & 3 & 0 \\ 1 & 0 & 4 \\ \end{bmatrix} \begin{bmatrix} a_0 \\ a_1 \\ a_2\end{bmatrix}$$
    La matrice associée à $g = f_1 \circ T\circ f_2^{-1}$ est donc $A = \begin{bmatrix} 2 & 3 & 0 \\ 1 & 0 & 4 \end{bmatrix}$ puisque $g(a) = Aa \ \forall a \in \R^3$.\\
    
    \noindent Cette composition de forme $h \circ F \circ \Tilde{h}^{-1}$ sera souvent utile durant le semestre pour étudier l'application $F$ en passant par $\R^n$.
    \item Echelonnons pour voir si la forme échelonnée compte un pivot par ligne:
    $$\begin{bmatrix} 
    2 & 3 & 0 \\ 
    1 & 0 & 4 
    \end{bmatrix} \overset{L_{1} \leftrightarrow L_{2}}{\sim} 
    \begin{bmatrix} 
    1 & 0 & 4 \\ 
    2 & 3 & 0 
    \end{bmatrix} \overset{L_{2} \rightarrow L_{2}-2L_{1}}{\sim} 
    \begin{bmatrix} 
    1 & 0 & 4 \\ 
    0 & 3 & -8 
    \end{bmatrix} \overset{L_{2} \rightarrow \frac{1}{3}L_2}{\sim}
    \begin{bmatrix} 
    1 & 0 & -4 \\ 
    0 & 1 & \frac{-8}{3} 
    \end{bmatrix}$$
    Le nombre de pivots est $2$, soit un pivot par ligne, donc l'application est surjective. D'autre part, la matrice ne possède pas un pivot par colonne, donc l'application n'est pas injective. Notons que la dernière étape arrivant à la forme échelonnée réduite à partir de la forme échelonnée n'est pas nécessaire ici, car tout ce qui nous importe est le nombre de pivots. \\
    
    \noindent Vous verrez plus tard dans le semestre que cette éventuelle surjectivité et/ou injectivité de $h \circ F \circ \Tilde{h}^{-1}$ avec $h, \Tilde{h}$ des isomorphimes (des fonctions bijectives et linéaires) sera équivalente à la surjectivité et/ou injectivité de $F$. Ainsi, ici, nous étudions $T$ à travers la matrice associée à $f_1 \circ T \circ f_2^{-1}$. \\
    
\end{enumerate}


\subsection*{Exercice 6}
\begin{enumerate}
    \item Pour un certain $x \neq 0$, $Ax=\lambda x$. Donc:
    $$Ax=\lambda x \implies Ax-\lambda x = 0 \implies Ax - \lambda I_nx = 0 \implies (A-\lambda I_n)x = 0$$
    La multiplication de $A-\lambda I_n$ par  $x$ nous donne le vecteur nul, ce qui signifie que $x \in \ker (A-\lambda I_n)$. Comme $x \neq 0$, $\ker (A-\lambda I_n) \neq \{0 \}$.
    \item Nous calculons $A-3I_3$:
    $$A-3I_3 = \begin{bmatrix} -2 & -4 & 2 \\ -2 & 1 & 2 \\ 4 & 2 & 5 \end{bmatrix} - \begin{bmatrix} 3 & 0 & 0 \\ 0 & 3 & 0 \\ 0 & 0 & 3 \end{bmatrix} = \begin{bmatrix} -5 & -4 & 2 \\ -2 & -2 & 2 \\ 4 & 2 & 2 \end{bmatrix}$$
    Echelonnons :
    $$\begin{bmatrix} -5 & -4 & 2 \\ 
    -2 & -2 & 2 \\ 
    4 & 2 & 2 
    \end{bmatrix} \sim 
    \begin{bmatrix} 
    1 & 4/5 & -2/5 \\ 
    -2 & 2 & 2 \\ 
    4 & 2 & 2 
    \end{bmatrix} \sim
    \begin{bmatrix} 
    1 & 4/5 & -2/5 \\ 
    0 & -2/5 & 6/5 \\ 
    0 & -6/5 & 18/5 
    \end{bmatrix} \sim
    \begin{bmatrix} 
    1 & 4/5 & -2/5 \\ 
    0 & -2 & 6 \\ 
    0 & -6 & 18 
    \end{bmatrix} $$
    $$\sim\begin{bmatrix} 
    5 & 4 & -2 \\ 
    0 & 6 & -18 \\ 
    0 & -6 & 18 
    \end{bmatrix} \sim
    \begin{bmatrix} 
    5 & 4 & -2 \\ 
    0 & 1 & -3 \\ 
    0 & 0 & 0 
    \end{bmatrix} \sim 
    \begin{bmatrix} 
    5 & 0 & 10 \\ 
    0 & 1 & -3 \\ 
    0 & 0 & 0 
    \end{bmatrix} \sim
    \begin{bmatrix} 
    1 & 0 & 2 \\ 
    0 & 1 & -3 \\ 
    0 & 0 & 0 
    \end{bmatrix}$$
    De ceci nous tirons le système linéaire :
    $\begin{cases}
    x_1 = -2x_3 \\
    x_2 = 3x_3\\
    x_3 \in \R
    \end{cases}$, le noyau est donc : $$\ker (A-3I_3) = \left\{ x_3\begin{bmatrix}
    -2 \\ 3 \\ 1
    \end{bmatrix} \ | \  x_3 \in \R \right\} \neq \{0\}$$
\end{enumerate}

\subsection*{Exercice 7}
\noindent Soit $A = \begin{bmatrix}
1 & b \\ 0 & 1 \end{bmatrix}$, et soit $(P_n): A^n = \begin{bmatrix} 1 & nb \\ 0 & 1 \end{bmatrix}$. \\
Pour $n=1$, $A^1 = \begin{bmatrix} 1 & b \\ 0 & 1 \end{bmatrix}$ et $A^1 = \begin{bmatrix} 1 & 1\cdot b \\ 0 & 1 \end{bmatrix}$, $(P_1)$ est vraie et donc $(P_n)$ est initialisée. \\

\noindent Soit maintenant $n\geq1$. Supposons $(P_n)$ vraie et montrons qu'elle implique $(P_{n+1})$:
$$A^n = \begin{bmatrix}
1 & nb \\ 0 & 1 \end{bmatrix} \implies A^{n+1} = A^n A = \begin{bmatrix}
1 & nb \\ 0 & 1 \end{bmatrix}  \begin{bmatrix}
1 & b \\ 0 & 1 \end{bmatrix} \implies A^{n+1} = \begin{bmatrix}
1\times 1 + 0\times nb & 1\times b + nb \times 1 \\ 0\times 1 + 1\times 0 & 0 \times b + 1 \times 1 \end{bmatrix} = \begin{bmatrix} 1 & (n+1)b \\ 0 & 1 \end{bmatrix}$$

\noindent $(P_{n+1})$ est vraie, et en conclusion, $\forall n \in \N_{\geq 1}$, $\forall b \in \R$, $A^n = \begin{bmatrix}
1 & nb \\ 0 & 1 \end{bmatrix}$. \\

\subsection*{Exercice 8}
\noindent $(AB)_{i,j}=\displaystyle\sum_{k=1}^{n}a_{i,k}b_{k,j}$. Mais par hypothèse, $A$ et $B$ sont diagonales, donc $a_{i,j} = 0$ si $i \neq j$, et de même $b_{i,j} = 0$ si $i \neq j$. \\
Ceci implique que $(AB)_{i,j} = 0$ si $i \neq j$, et donc que $AB$ est diagonale. Plus visuellement : 
\begin{align*}
AB &= \begin{bmatrix}
a_{1,1} & 0 & 0 & \cdots & 0\\
0 & a_{2,2} & 0 & \cdots & 0 \\
\vdots & &\ddots & & \vdots \\
0 & 0 & \cdots & a_{n-1, n-1} & 0\\
0 & 0 &\cdots& 0 & a_{n,n}
\end{bmatrix}
\begin{bmatrix}
b_{1,1} & 0 & 0 & \cdots & 0\\
0 & b_{2,2} & 0 & \cdots & 0 \\
\vdots & &\ddots & & \vdots \\
0 & 0 & \cdots & b_{n-1, n-1} & 0\\
0 & 0 &\cdots& 0 & b_{n,n}
\end{bmatrix}\\
&= \begin{bmatrix}
b_{1,1}a_{1,1} & 0a_{1,1} & 0a_{1,1} & \cdots & 0a_{1,1}\\
0a_{2,2} & b_{2,2}a_{2,2} & 0a_{2,2} & \cdots & 0a_{2,2} \\
\vdots & &\ddots & & \vdots \\
0a_{n-1, n-1} & 0a_{n-1, n-1} & \cdots & b_{n-1, n-1}a_{n-1, n-1} & 0a_{n-1, n-1}\\
0a_{n,n} & 0a_{n,n} &\cdots& 0a_{n,n} & b_{n,n}a_{n,n}
\end{bmatrix}\\
&= \begin{bmatrix}
a_{1,1}b_{1,1} & 0 & 0 & \cdots & 0\\
0 & a_{2,2}b_{2,2} & 0 & \cdots & 0 \\
\vdots & &\ddots & & \vdots \\
0 & 0 & \cdots & a_{n-1,n-1}b_{n-1, n-1} & 0\\
0 & 0 &\cdots& 0 & a_{n,n}b_{n,n}
\end{bmatrix}
\end{align*}

\subsection*{Exercice 9}
\noindent $(AB)_{i,j}=\displaystyle\sum_{k=1}^{n}a_{i,k}b_{k,j}$ \\
Or d'après les hypothèses $b_{k,j}$ et $a_{i,k}$ sont nuls si $i>k$ et $k>j$. Ainsi il suit que si $i>j$ alors $(AB)_{i,j}=0$, et donc que $AB$ est triangulaire supérieure. Plus visuellement :
\begin{align*}
AB &= \begin{bmatrix}
a_{1,1} & a_{1,2} & a_{1,3} & \cdots & a_{1,n} \\
  & a_{2,2} & a_{2,3} & \cdots & a_{2,n} \\
  &   & \ddots & \ddots & \vdots \\
  & \bigzero  &  & \ddots & \vdots \\
  &   &   &  & a_{n,n}
\end{bmatrix}
 \begin{bmatrix}
b_{1,1} & b_{1,2} & b_{1,3} & \cdots & b_{1,n} \\
  & b_{2,2} & b_{2,3} & \cdots & b_{2,n} \\
  &   & \ddots & \ddots & \vdots \\
  & \bigzero  &  & \ddots & \vdots \\
  &   &   &  & b_{n,n}
\end{bmatrix}\\
&= \begin{bmatrix}
A\begin{bmatrix}
b_{1,1} \\ 0 \\ \vdots \\ 0
\end{bmatrix} & 
A\begin{bmatrix}
b_{1,2} \\ b_{2,2} \\ \vdots \\ 0
\end{bmatrix} &
\cdots &
A \begin{bmatrix}
b_{1,n} \\ b_{2,n} \\ \vdots\\ b_{n,n}
\end{bmatrix}
\end{bmatrix}\\
&= \begin{bmatrix}
a_{1,1}b_{1,1} &a_{1,1} b_{1,2} + a_{1,2}b_{2,2}  & \cdots & \sum_{k = 1}^n a_{1, k}b_{k, n} \\
  & a_{2,2}b_{2,2}  & \cdots & \sum_{k = 2}^n a_{2,k}b_{k,n} \\
  &   & \ddots & \vdots \\
  & \bigzero  & & \vdots \\
  &   &   &   a_{n,n}b_{n,n}
\end{bmatrix}
\end{align*}

\subsection*{Exercice 10}
% \noindent $A=\displaystyle\frac{A+A^{T}}{2}+\frac{A-A^{T}}{2}$.
\begin{enumerate}
    \item $(AB)_{i,j}=\displaystyle\sum_{k=1}^{n}a_{i,k}b_{k,j}$ \\
    Donc :
    $$[(AB)^{T}]_{i,j}=(AB)_{j,i}=\sum_{k=1}^{n}a_{j,k}b_{k,i}$$
    En notant $c_{i,j}$ les éléments de $A^{T}$ et $d_{i,j}$ les éléments de $B^{T}$ nous pouvons réécrire la dernière somme de la manière suivante, puisque $c_{k,j} = a_{j,k}$ et $d_{i,k} = b_{k,i}$ :
    $$\sum_{k=1}^{n}c_{k,j}d_{i,k}=\sum_{k=1}^{n}d_{i,k}c_{k,j}=(B^{T}A^{T})_{i,j}$$
    Donc $[(AB)^T]_{i,j} = (B^T A^T)_{i,j}$, et donc $(AB)^T = B^T A^T$.
    \item Il suffit de remarquer que toute matrice triangulaire inférieure est la transposée d'une matrice triangulaire supérieure. \\
    En effet, soient $A,B \in \R^{n\cross n}$ deux matrices triangulaires supérieures. Nous savons que, par l'exercice 9, leur produit $AB$ est aussi une matrice triangulaire supérieure. Donc:
    $$\underbrace{(AB)^T}_{\text{triang. inf}} = \underbrace{B^T}_{\text{triang. inf}} \cdot  \underbrace{A^T}_{\text{triang. inf}}$$
    \item Soit $A \in \R^{n \cross n}$. Nous voulons trouver $S \in \R^{n \cross n}$ et $Q \in \R^{n \cross n}$ telles que $A = S+Q$, $S$ symétrique et $Q$ antisymétrique, i.e : $s_{i,j} = s_{j,i}$ et $q_{i,j} = -q_{j,i}$. L'idée sera de rassmembler tout ce que nous savons sur $s_{i,j}$ et $q_{i,j}$.\\
    Ainsi, nous posons : $a_{i,j} = s_{i,j} + q_{i,j}$. Remarquons également : $a_{j,i} = s_{j,i} + q_{j,i} = s_{i,j} - q_{i,j}$. Nous obtenons ainsi le système linéaire suivant, avec inconnues $s_{i,j}$ et $q_{i,j}$ :
    $$
    \begin{cases}
    s_{i,j} + q_{i,j} = a_{i,j}\\
    s_{i,j} - q_{i,j} = a_{j,i}
    \end{cases}
    $$
    Que nous pouvons réécrire sous forme d'équation matricielle :
    $$
    \begin{bmatrix}
    1 & 1\\
    1 & -1
    \end{bmatrix}\begin{bmatrix}
    s_{i,j} \\ q_{i,j}
    \end{bmatrix}=\begin{bmatrix}
    a_{i,j} \\ a_{j,i}
    \end{bmatrix}
    $$
    Résolvons en calculant la forme échelonnée réduite de la matrice augmentée :
    $$
    \begin{bmatrix}
    1 & 1 & \bigm| & a_{i,j}\\
    1 & -1 & \bigm| & a_{j,i}
    \end{bmatrix} \sim
    \begin{bmatrix}
    1 & 1 & \bigm| & a_{i,j}\\
    0 & -2 & \bigm| & a_{j,i} - a_{i,j}
    \end{bmatrix}\sim
    \begin{bmatrix}
    1 & 1 & \bigm| & a_{i,j}\\
    0 & 1 & \bigm| & \frac{a_{i,j} - a_{j,i}}{2}
    \end{bmatrix}\sim
    \begin{bmatrix}
    1 & 0 & \bigm| &\frac{a_{i,j} + a_{j,i}}{2}\\
    0 & 1 & \bigm| & \frac{a_{i,j} - a_{j,i}}{2}
    \end{bmatrix}
    $$
    Ainsi la solution unique de ce système est donnée par :
    $$
    (*) : \begin{cases}
    s_{i,j} = \frac{a_{i,j} + a_{j,i}}{2}\\
    q_{i,j} = \frac{a_{i,j} - a_{j,i}}{2}
    \end{cases}
    $$
    En conclusion :
    $$
    \begin{cases}
    S = \frac{1}{2}(A + A^T)\\
    Q = \frac{1}{2}(A - A^T)
    \end{cases}
    $$
    Nous vérifions bien que $A$ est la somme de ces 2 matrices:
    $$
    S + Q = \frac{1}{2}(A + A^T) + \frac{1}{2}(A - A^T) = A + A^T - A^T = A
    $$
    Puis, nous vérifions bien que $S$ et $Q$ sont respectivement symétrique et antisymétrique par $(*)$ : 
    $$
    \begin{cases}
    s_{j,i} = \frac{a_{j,i}+a_{i,j}}{2} = \frac{a_{i,j} + a_{j,i}}{2} = s_{i,j}\\
    -q_{j,i} = -\frac{a_{j,i} - a_{i,j}}{2} = \frac{a_{i,j} - a_{j,i}}{2} = q_{i,j}
    \end{cases}
    $$
    Remarque : nous aurions pu deviner les matrices $S$ et $Q$ puis montrer leur validité, nous avons présenté ici un moyen de les trouver afin d'illustrer jusqu'où simplement lire la donnée et écrire toutes les informations qui en découlent nous mène.\\
    
    \noindent Notons que nous pourrions montrer que, pour $C, D \in \R^{p \cross n}$ :
    $$(C + D)^T = C^T + D^T
    $$
\end{enumerate}

\subsection*{Exercice 11}
\begin{enumerate}
    \item Il suffit d'écrire les formules des éléments diagonaux de $C=AB$ puis $D=BA$ et ensuite comparer, en passant par une permutation de deux sommes finies. \\
    En effet: 
    $$\Tr(AB) = \sum_{i=1}^{n} (AB)_{i,i} = 
    \sum_{i=1}^{n}\sum_{k=1}^{n}a_{i,k}b_{k,i}= \sum_{k=1}^{n}\sum_{i=1}^{n}a_{i,k}b_{k,i} = \sum_{k=1}^{n}\sum_{i=1}^{n}b_{k,i}a_{i,k} = \sum_{k=1}^{n} (BA)_{k,k} = \Tr(BA)$$
    \item En posant $D=AB$, il suit d'après la question précédente que $\Tr(ABC)=\Tr(DC)=\Tr(CD)=\Tr(CAB)$.
    \item  
    $ABC = \begin{bmatrix}
    2&3\\
    2&4\\
    \end{bmatrix}
    \begin{bmatrix}
    1&3\\
    0&0 \\
    \end{bmatrix} 
    \begin{bmatrix}
    1&2\\
    0&0 \\
    \end{bmatrix} = 
    \begin{bmatrix}
    2&4\\
    2&4 \end{bmatrix}, \ ACB = \begin{bmatrix}
    2&3\\
    2&4\\
    \end{bmatrix}  
    \begin{bmatrix}
    1&2\\
    0&0 \\
    \end{bmatrix} 
    \begin{bmatrix}
    1&3\\
    0&0 \\
    \end{bmatrix} = 
    \begin{bmatrix}
    2&6\\
    2&6\\
    \end{bmatrix}$ \newline \newline
Il est clair que les traces de ces deux matrices ne sont pas égales : $\Tr(ABC) = 2+4 = 6$ et $\Tr(ACB) = 2 + 6 = 8$.
\end{enumerate}

\begin{center}
    \includegraphics[width=50px,height =50px]{logo.jpg}
\end{center}

% ANCIEN EXO 7
%\noindent On raisonne par récurrence: \\
%Pour $n=1$ c'est vrai. \\
%Supposons cette assertion vérifiée au rang $n$ montrons %qu'elle est vraie au rang $n+1$:
%$$(A+B)^{n+1}=(A+B)^{n}(A+B)=(\sum_{k=0}^{n}C_n^kA^{k}B^{n-k})(A+B)=\sum_{k=0}^{n}C_n^kA^{k}B^{n-k}A+\sum_{k=0}^{n}C_n^kA^{k}B^{n-k+1}$$
%Comme $AB=BA$ on peut réécrire :
%$$\sum_{k=0}^{n}C_n^kA^{k+1}B^{n-k}+\sum_{k=0}^{n}C_n^kA^{k}B^{n-k+1}$$
%En faisant le changement d'indices $k'=k+1$ on obtient :
%$$\sum_{k'=1}^{n+1}C_n^{k'-1}A^{k'}B^{n+1-k'}+\sum_{k=0}^{n}C_n^kA^{k}B^{n-k+1}=A^{n+1}+\sum_{k=1}^{n}(C_n^{k-1}+C_n^{k})A^{k}B^{n+1-k}+B^{n+1}$$
%Comme $C_n^{k-1}+C_n^{k}=C_{n+1}^{k}$ la dernière somme se réécrit :
%$$\displaystyle\sum_{k=0}^{n}C_{n+1}^{k}A^{k}B^{n+1-k}$$
%ce qui conclut la récurrence. \\

\end{document}
